# Axiom Project - Strict Working Rules

## üö® MANDATORY RULES - NO EXCEPTIONS

### Rule #1: NEVER Change Working Directory

**STRICT REQUIREMENT**: All commands MUST be executed from project root:
```
/home/sandeep/pertinent/axiom
```

**FORBIDDEN**:
- ‚ùå `cd` commands in any form
- ‚ùå `cwd` parameter in execute_command
- ‚ùå Changing to subdirectories like axiom/database, axiom/mcp, etc.

**ALLOWED**:
- ‚úÖ Use full relative paths from root: `axiom/database/docker-compose.yml`
- ‚úÖ Commands with path prefixes: `docker compose -f axiom/database/docker-compose.yml`
- ‚úÖ Multi-command with paths: `ls axiom/mcp/servers && cat axiom/database/models.py`

**Examples**:

**WRONG**:
```bash
cd axiom/database && docker compose up -d  # ‚ùå Changes directory
```

**CORRECT**:
```bash
docker compose -f axiom/database/docker-compose.yml up -d  # ‚úÖ Stays in root
```

**WRONG**:
```bash
cd axiom/mcp && docker compose build  # ‚ùå Changes directory
```

**CORRECT**:
```bash
docker compose -f axiom/mcp/docker-compose.yml build  # ‚úÖ Stays in root
```

### Rule #2: .env File MUST Be Created Early

**REQUIREMENT**: `.env` file creation is step #3 in setup:
1. Clone repo
2. Create venv
3. **Run `python setup_environment.py`** (creates .env, validates)
4. Install packages
5. Start databases

**Why**: System has fallback defaults that can mask missing .env file. This is dangerous for production.

### Rule #3: Always Use Full Paths for File Operations

**REQUIREMENT**: When reading/writing files, always use paths relative to `/home/sandeep/pertinent/axiom`

**Examples**:
- ‚úÖ `axiom/database/models.py`
- ‚úÖ `demos/demo_complete_data_infrastructure.py`
- ‚ùå `../axiom/models.py` (relative navigation)
- ‚ùå `/tmp/test.py` (absolute paths outside project)

### Rule #4: Verify Terminal Output Quickly

**REQUIREMENT**: When terminal shows `<VSCE exit code is undefined>`, command has completed. Proceed immediately, don't wait.

This is a VSCode terminal communication issue, not a command execution issue.

### Rule #5: NEVER Push Directly to Main Branch

**STRICT REQUIREMENT**: All code changes MUST go through feature branches and pull requests.

**Git Workflow (MANDATORY)**:
```bash
# 1. Create feature branch
git checkout -b feature/descriptive-name

# 2. Make changes and commit
git add .
git commit -m "Clear commit message"

# 3. Push to feature branch
git push origin feature/descriptive-name

# 4. Create PR to merge to main
# Only merge to main after PR review/approval
```

**FORBIDDEN**:
- ‚ùå `git push origin main` (direct push to main)
- ‚ùå `git commit` on main branch
- ‚ùå Working directly on main branch

**ALLOWED**:
- ‚úÖ Create feature branches
- ‚úÖ Push to feature branches
- ‚úÖ Merge to main via approved PRs only

**Why**: Protects main branch integrity, enables code review, maintains project history.

### Rule #6: No Temporary Documentation Files

**FORBIDDEN**: Creating multiple .md files for every small task

**ALLOWED**: 
- Official documentation in `docs/`
- Session handoff documents (1 per session)
- Critical architecture documents

**FORBIDDEN**:
- ‚ùå `NEW_WORKSTATION_SETUP.md`, `COMPLETE_SYSTEM_STATUS.md`, etc. for setup tasks
- ‚ùå Multiple summary documents for same topic
- ‚ùå Temporary test/validation .md files

Use README.md or existing docs instead.

### Rule #7: ALWAYS Verify Virtual Environment is Activated

**STRICT REQUIREMENT**: Before executing ANY Python command, verify venv is activated.

**Check Method**:
```bash
# Verify venv is active
which python  # Should show: /home/sandeep/pertinent/axiom/.venv/bin/python
```

**If NOT activated**:
```bash
source .venv/bin/activate  # Manual activation
# Or rely on autoenv if configured
```

**FORBIDDEN**:
- ‚ùå Running Python commands without venv active
- ‚ùå Using system Python instead of project venv
- ‚ùå Assuming venv is active without checking

**REQUIRED for every terminal session**:
```bash
# At start of session, ALWAYS:
python --version  # Should show: Python 3.13.9
which python      # Should show: .venv/bin/python
```

**Why**:
- Using system Python = wrong packages
- Missing dependencies = runtime errors
- Package version conflicts
- Corrupted environment

**Note**: Autoenv (`.autoenv` file) auto-activates venv on `cd` to project root. If not working, always activate manually first.

### Rule #8: FIX ROOT CAUSES - PREVENT RECURRENCE

**CRITICAL PRINCIPLE**: Every fix must address the ROOT CAUSE, not just symptoms.

**MANDATORY Approach**:
- **Identify**: What's the underlying cause, not just the symptom?
- **Design**: How can we prevent this class of issues permanently?
- **Implement**: Fix it once, correctly, completely
- **Validate**: Ensure it can't happen again

**Examples from This Project**:

**Bad** ‚ùå: Fix one Dockerfile path issue
**Good** ‚úÖ: Create script to update all 12 Dockerfiles + document pattern

**Bad** ‚ùå: Add missing import to one file
**Good** ‚úÖ: Use sed to fix all 10 files + ensure pattern is clear

**Bad** ‚ùå: Manually fix container healthcheck
**Good** ‚úÖ: Update docker-compose.yml template + document why

**FORBIDDEN**:
- ‚ùå Band-aid fixes that need repeating
- ‚ùå Fixing symptoms instead of causes
- ‚ùå "Quick fixes" that break later
- ‚ùå Solving same problem multiple times

**REQUIRED**:
- ‚úÖ Systematic solutions (scripts, templates, patterns)
- ‚úÖ Documentation of WHY (prevent recurrence)
- ‚úÖ Validation that fix is complete
- ‚úÖ Future-proof design

**When fixing bugs**:
1. Ask: "Why did this happen?"
2. Ask: "How can this entire class of bugs be prevented?"
3. Implement systemic fix
4. Document for future developers
5. Add validation/checks to prevent regression


### Rule #9: NEVER Commit Credentials to Git

**CRITICAL SECURITY RULE**: Credentials, API keys, passwords, and secrets MUST NEVER be committed to git.

**MANDATORY Practice**:
- ‚úÖ Store ALL credentials in `.env` file (already gitignored)
- ‚úÖ Use environment variables: `os.getenv('API_KEY')`
- ‚úÖ Provide `.env.example` template (with placeholder values)
- ‚úÖ Verify `.gitignore` includes all credential files

**FORBIDDEN**:
- ‚ùå Hardcoding API keys in source code
- ‚ùå Committing .env file to git
- ‚ùå Passwords in docker-compose.yml (use ${VARIABLE} references)
- ‚ùå Database credentials in Python files
- ‚ùå Secrets in configuration files

**Required Files**:
```
.env                    # Real credentials (gitignored) ‚úÖ
.env.example            # Template format (committed) ‚úÖ
.gitignore              # Must include .env ‚úÖ
```

**Examples**:

**WRONG** ‚ùå:
```python
# In source code - NEVER DO THIS
ANTHROPIC_API_KEY = "sk-ant-api03-xxxxx"  # ‚ùå Exposed in git!
DB_PASSWORD = "axiom_secret_password"     # ‚ùå Security breach!
```

**CORRECT** ‚úÖ:
```python
# Use environment variables
import os
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')  # ‚úÖ From .env
DB_PASSWORD = os.getenv('POSTGRES_PASSWORD')        # ‚úÖ Secure
```

**Validation Before Commit**:
```bash
# ALWAYS check before committing
git diff | grep -i "password\|api_key\|secret\|token"

# If any matches found, DO NOT COMMIT
```

### Rule #10: Credential Files Must Have Example Templates

**REQUIREMENT**: Every file containing credentials MUST have a corresponding `.example` template file.

**Pattern**:
```
.env                  # Real credentials (gitignored)
.env.example          # Template (committed to git)

config.json           # Real config (gitignored if contains secrets)
config.json.example   # Template (committed)
```

**Template File Requirements**:
1. **Same structure** as real file
2. **Placeholder values** (not real credentials)
3. **Clear comments** explaining what each value is for
4. **Example format** showing expected value types

**Example - .env.example**:
```bash
# Database Credentials
POSTGRES_USER=axiom
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=axiom_finance

# API Keys (get from provider websites)
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxxxxxxxxxxx
POLYGON_API_KEY=your_polygon_key_here

# Format: Keep variable names, replace values with descriptive placeholders

### Rule #11: ALWAYS Leverage Existing Open-Source Solutions

**CRITICAL PRINCIPLE**: Never reinvent the wheel. Use battle-tested open-source tools instead of writing custom code.

**MANDATORY Approach**:
1. **Search first**: Is there an open-source solution already?
2. **Evaluate**: Does it meet 80%+ of requirements?
3. **Integrate**: Use existing tools via pip/docker/npm
4. **Customize**: Only add small wrapper/config, not full implementation

**FORBIDDEN**:
- ‚ùå Writing custom implementations of common functionality
- ‚ùå Building features that exist in popular libraries
- ‚ùå Reinventing standard tools (logging, monitoring, viz, etc.)
- ‚ùå "Not invented here" syndrome

**REQUIRED**:
- ‚úÖ Search GitHub, PyPI, npm before coding
- ‚úÖ Use established libraries (Apache, Linux Foundation projects preferred)
- ‚úÖ Contribute improvements back to open-source if needed
- ‚úÖ Write ONLY unique business logic

**Examples from This Project**:

**BAD** ‚ùå: Wrote custom 3D graph viewer (FastAPI + custom viz)
**GOOD** ‚úÖ: Should have used:
- Gephi (desktop app, export from Neo4j)
- Graphistry (Docker image, GPU-accelerated)
- yEd (free desktop tool)
- Or Neo4j Bloom (if acceptable)

**BAD** ‚ùå: Writing custom monitoring system
**GOOD** ‚úÖ: Use Prometheus + Grafana (industry standard)

**BAD** ‚ùå: Custom job scheduler
**GOOD** ‚úÖ: Use Apache Airflow (battle-tested)

**BAD** ‚ùå: Custom streaming solution
**GOOD** ‚úÖ: Use Kafka or Redis Streams

**For Neo4j Visualization Specifically**:

**Open-Source Options We Should Use**:
```bash
# Option 1: Gephi (Desktop)
# - Free, powerful, widely used
# - Export from Neo4j, visualize in Gephi
# - No code needed!

# Option 2: Graphistry (Docker)
docker pull graphistry/graphistry-forge-base
# - GPU-accelerated 3D viz
# - Open-source core
# - Docker container ready

# Option 3: NetworkX + Plotly (Python)
pip install networkx plotly
# - Pure Python
# - Existing ecosystem
# - ~20 lines of code vs 200 we wrote

# Option 4: Neo4j Browser (Built-in)
# - Already running at localhost:7474
# - Free, from Neo4j itself
# - No installation needed
```

**The Rule**:
- Search "neo4j 3d visualization open source" BEFORE writing code
- Find: Gephi, Graphistry, etc.
- Use one of those
- Save 90% development time

**How to Check**:
```bash
# Before writing ANY new feature, search:
# 1. GitHub: "topic:neo4j topic:visualization"
# 2. PyPI: search "neo4j graph visualization"
# 3. Docker Hub: search "neo4j visualization"
# 4. Ask Claude: "What are popular open-source tools for [feature]?"

### Rule #12: ALWAYS Use `uv add` for Dependencies

**CRITICAL REQUIREMENT**: All package installations MUST use `uv add`, not `uv pip install`.

**MANDATORY Practice**:
- ‚úÖ `uv add package-name` (updates pyproject.toml + uv.lock)
- ‚ùå `uv pip install package-name` (doesn't update lock file)

**Why This Matters**:
- `uv add` updates both pyproject.toml and uv.lock
- Lock file ensures reproducible builds
- Other developers get exact same versions
- Prevents "works on my machine" issues

**Examples**:

**WRONG** ‚ùå:
```bash
uv pip install langgraph  # Not tracked in lock file!
uv pip install pyvis      # Dependencies not locked!
```

**CORRECT** ‚úÖ:
```bash
uv add langgraph  # Updates pyproject.toml + uv.lock
uv add pyvis      # Locks all dependencies
```

**Lock File Benefits**:
- Exact version reproducibility
- Dependency conflict detection
- Security vulnerability tracking
- Team synchronization
- CI/CD reliability

**When Installing Multiple Packages**:
```bash
# WRONG
uv pip install langgraph langchain-anthropic pyvis

# CORRECT  
uv add langgraph langchain-anthropic pyvis
```

**To sync from lock file** (other developers):
```bash
uv sync  # Installs exact versions from uv.lock
```

**ALWAYS**: After `uv add`, commit both pyproject.toml AND uv.lock to git.

```

**When Custom Code is OK**:
- ‚úÖ Unique business logic (quant models, trading strategies)
- ‚úÖ Integration glue (connecting two systems)
- ‚úÖ Project-specific workflows
- ‚úÖ When truly no existing solution exists

**When Custom Code is NOT OK**:
- ‚ùå Standard features (viz, monitoring, scheduling, etc.)
- ‚ùå Common utilities (logging, config, etc.)
- ‚ùå Infrastructure (databases, queues, etc.)

**This project must maximize leverage of open-source ecosystem** - write ONLY what's unique to Axiom.

```

**REQUIRED When Adding New Secrets**:
1. Add to `.env` (gitignored)
2. Add placeholder to `.env.example` (committed)
3. Update `.gitignore` if new file type
4. Document in setup guide

**Why This Matters**:
- New developers can set up quickly
- No guessing what credentials are needed
- No accidental credential exposure
- Easy credential rotation
- Industry-standard security practice

**This project must be maintenance-free** - fix it once, fix it right, never revisit.

---

## Enforcement

These rules are STRICT and MANDATORY for all work on this project.

Violations will result in:
- Broken terminal state
- File path confusion
- Documentation bloat
- Harder maintenance

**When in doubt, stay in `/home/sandeep/pertinent/axiom` and use relative paths!**