# Data Pipeline Services - Docker Compose
# All pipelines run as separate containers

version: '3.8'

services:
  # Real-time data ingestion pipeline
  data-ingestion:
    build:
      context: ../..
      dockerfile: axiom/pipelines/Dockerfile.ingestion
    container_name: axiom-pipeline-ingestion
    environment:
      - PYTHONPATH=/app
      - PIPELINE_NAME=realtime-ingestion
      - PIPELINE_INTERVAL=60
      - SYMBOLS=AAPL,MSFT,GOOGL,TSLA,NVDA
      # Database connections from .env
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=${POSTGRES_USER:-axiom}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-axiom_password}
      - POSTGRES_DB=${POSTGRES_DB:-axiom_finance}
      - REDIS_HOST=redis
      - REDIS_PASSWORD=${REDIS_PASSWORD:-axiom_redis}
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-axiom_neo4j}
    networks:
      - axiom_network
      - database_axiom_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

networks:
  axiom_network:
    external: true
    name: axiom-mcp-network
  database_axiom_network:
    external: true
    name: database_axiom_network

# Usage:
# Start pipeline: docker-compose -f axiom/pipelines/docker-compose.yml up -d
# View logs: docker-compose -f axiom/pipelines/docker-compose.yml logs -f data-ingestion
# Stop: docker-compose -f axiom/pipelines/docker-compose.yml down